name: Run GPT-J

# Controls when the workflow will run
on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  run_gptj:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Step 1: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      # Step 2: Install dependencies (Torch and Transformers libraries)
      - name: Install dependencies
        run: |
          pip install torch transformers

      # Step 3: Run GPT-J
      - name: Run GPT-J
        run: |
          python -c "from transformers import AutoModelForCausalLM, AutoTokenizer; \
          model = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-j-6B'); \
          tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-j-6B'); \
          inputs = tokenizer('Hello, how can I assist you?', return_tensors='pt'); \
          outputs = model.generate(**inputs); \
          print(tokenizer.decode(outputs[0]))"
